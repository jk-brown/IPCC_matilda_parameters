---
title: "Running model with low ECS"
author: "Joe Brown"
date: "2025-03-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set-up

Source files in `set-up` folder.

```{r}
source("set-up/source_all.R")
```

# Generate Initial Parameters

Generate initial parameters to be used for model runs.

Load .ini files:
```{r}
# ini directory 
ini_dir <- paste0(system.file("input", package = "hector"), "/")

# read ini files into a list 
ini_list <- list("SSP1-1.9" = paste0(ini_dir, "hector_ssp119.ini"), 
                 "SSP1-2.6" = paste0(ini_dir, "hector_ssp126.ini"), 
                 "SSP2-4.5" = paste0(ini_dir, "hector_ssp245.ini"), 
                 "SSP3-7.0" = paste0(ini_dir, "hector_ssp370.ini"), 
                 "SSP5-8.5" = paste0(ini_dir, "hector_ssp585.ini"))

```

Build perturbed parameter ensemble:
```{r}
# set seed for replication
set.seed(444)

# set sample size
n = 7500

# initiate a core using one of the ini files
param_core <- newcore(ini_list[[3]])

# generate parameters using default sampling
params <- generate_params(core = param_core, draws = n)

```

Sample new ECS distribution for "low-ECS":
```{r}
# sample new low-ECS distribution
low_ecs_sample <- rlnorm(n, lognorm(2.7, 0.7)[1], lognorm(2.7, 0.7)[2])

# Add new ECS samples 
params$ECS <- low_ecs_sample

```

Check ECS histogram to see what this distribution looks like:

```{r}
summary(params$ECS)  # Check distribution stats

hist(params$ECS, breaks = 50, main = "Histogram of Low-ECS Samples")  # Visualize
```

# Save Job

Save initial parameter set:
```{r}
params_dir <- here("data", "parameters")

file_name <- "initial_parameters_low_ecs.csv"

write.csv(params, file.path(params_dir, file_name), row.names = FALSE)

```

# Run the model with new "low-ECS" parameters

## Split parameters into separate jobs

Slit parameters into jobs -- will be a list:

```{r}
# splitting params

param_chunks <- split(params, 1:100)

```

## Set up: Parallel Computing

```{r}

# Set-up: Parallel computing 

# number of cores to put in cluster
cpu_cores <- detectCores() - 1

# intialize cluster
cl <- makeCluster(cpu_cores)

# export functions and objects needed to run model
exp <- c("param_chunks", 
         "ini_list", 
         "newcore", 
         "iterate_model")

clusterExport(cl, exp)

```

## Run model using parallel

```{r}
# Run model in parallel mode
result <- parLapply(cl, names(ini_list), function(scenario_name) {
  
  library(hector)  # or any required package
  
  # store data in scenario object
  scenario <- ini_list[[scenario_name]]
  # initialize core with the names of the current scenario
  core <- newcore(scenario, name = scenario_name)
  
  # run model for each param chunk for the current core 
  result_list <- lapply(param_chunks, function(chunk) {
    
    iterate_model(core = core, 
                  params = chunk, 
                  save_years = 1800:2200, 
                  save_vars = c("global_tas", 
                                "gmst", 
                                "CO2_concentration", 
                                "ocean_uptake"))
  })
  
  return(result_list)
  
})

# Add names to the list 
names(result) <- names (ini_list)

stopCluster(cl)
```

```{r}
# ensure correct run_number from one chunk to the next
# Loop over each scenario in result
for (scenario_name in names(result)) {
  
  scenario_list <- result[[scenario_name]]  # Extract the list of 100 chunks
  max_run_number <- 0  # Start counting from 1
  
  for (i in seq_along(scenario_list)) {
    scenario_list[[i]]$run_number <- scenario_list[[i]]$run_number + max_run_number
    max_run_number <- max(scenario_list[[i]]$run_number)  # Update max for next chunk
  }
  
  # Store the updated scenario back in result
  result[[scenario_name]] <- scenario_list
}
```

Find NAs:
```{r}
## Find NAs

na_runs <- list()  # Initialize empty list

# Loop over each scenario
 for (scenario_name in names(result)) {
     
     scenario_list <- result[[scenario_name]]  # Extract list of 100 chunks
     
     # Extract run numbers where there are NAs
     na_run_numbers <- unlist(lapply(scenario_list, function(df) {
         df$run_number[rowSums(is.na(df)) > 0]  # Get run_number where any column has NA
     }))
     
     # Store results for this scenario
     if (length(na_run_numbers) > 0) {
         na_runs[[scenario_name]] <- unique(na_run_numbers)  # Store only unique run numbers
     }
 }

# Print summary of NA runs
 print(na_runs)
```

Bind results into a new `model_result` object:
```{r}
# bind chunked results into a df for each scenario
model_result <- lapply(result, function(scenario) {
  
  bound_result <- do.call(rbind, scenario)

  return(bound_result)

})

```

## Testing removing NAs from all scenarios -- this means any runs with NAs in the higher SSPs will be removed from all scenario runs.
```{r}
# Step 1: Identify all run_numbers with NA in any scenario
na_run_numbers <- unique(unlist(lapply(model_result, function(df) {
  df$run_number[rowSums(is.na(df)) > 0]  # Extract run numbers with NA
})))

print(na_run_numbers)

# Step 2: Remove these run_numbers from all scenario data frames
model_result <- lapply(model_result, function(df) {
  df[!df$run_number %in% na_run_numbers, ]  # Keep only valid runs
})

# Print the number of removed runs
cat("Removed", length(na_run_numbers), "runs due to NA values across all scenarios.\n")

# All scenarios should have the same number of records now
# Check that all scenarios have the same number of runs
sapply(model_result, nrow)

```

## Save job

```{r}
result_dir <- here("output", "model_results")

file_name <- "initial_result_low_ecs.RDS"

saveRDS(model_result, file.path(result_dir, file_name))

```


